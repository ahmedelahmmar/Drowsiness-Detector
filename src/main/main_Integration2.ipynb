{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pygame\n",
    "from scipy.spatial import distance as dist\n",
    "face_classifer = joblib.load(\"FaceClassifier_HoG(64, 64)(16, 16)(8, 8)(0.95).pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = (64, 64) \n",
    "block_size = (16, 16)\n",
    "block_stride = (8, 8)\n",
    "cell_size = (8, 8)\n",
    "num_bins = 9\n",
    "yawn_counter = 0\n",
    "HaarCascade=1\n",
    "\n",
    "lower_color = np.array([100, 50, 0], dtype=np.uint8)\n",
    "upper_color = np.array([205, 130, 130], dtype=np.uint8)\n",
    "\n",
    "\n",
    "HOG = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, num_bins)\n",
    "# Initialize pygame mixer\n",
    "pygame.mixer.init()\n",
    "# Load the buzzer sound\n",
    "buzzer_sound = pygame.mixer.Sound(\"cristiano-ronaldo-siuu-made-with-Voicemod-technology.mp3\")\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def calculate_mouth_aspect_ratio(mouth):\n",
    "    x, y, w, h = cv2.boundingRect(mouth)\n",
    "    aspect_ratio = w // h\n",
    "    return aspect_ratio\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "\n",
    "def extract_features_face_detection(Image):\n",
    "\n",
    "    gray_image = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    equalized_image = cv2.equalizeHist(gray_image)\n",
    "\n",
    "    resized_image = cv2.resize(equalized_image, win_size)\n",
    "        \n",
    "    feature = HOG.compute(resized_image).flatten()\n",
    "\n",
    "    if feature.max() > 0:\n",
    "        feature /= feature.max()\n",
    "\n",
    "    return feature\n",
    "\n",
    "\n",
    "\n",
    "def union_boxes_min_max(boxes, min_x, min_y, max_x, max_y):\n",
    "  overall_box = None\n",
    "\n",
    "  if not overall_box:\n",
    "    for box in boxes:\n",
    "      x_min, y_min, x_max, y_max = box\n",
    "      min_x = min(min_x, x_min)\n",
    "      min_y = min(min_y, y_min)\n",
    "      max_x = max(max_x, x_max)\n",
    "      max_y = max(max_y, y_max)\n",
    "    overall_box = (min_x, min_y, max_x, max_y)\n",
    "    \n",
    "    return overall_box\n",
    "\n",
    "\n",
    "\n",
    "def filter_boxes_with_skin_mask(boxes, skin_mask):\n",
    "  filtered_boxes = []\n",
    "  for box in boxes:\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    \n",
    "    box_area = (x_max - x_min) * (y_max - y_min)\n",
    "    \n",
    "    intersection_mask = skin_mask[y_min:y_max, x_min:x_max]\n",
    "    intersection_area = cv2.countNonZero(intersection_mask)\n",
    "    \n",
    "    iou = intersection_area / box_area\n",
    "\n",
    "    # Define threshold for acceptable overlap with skin mask\n",
    "    threshold = 0.5\n",
    "\n",
    "    if iou >= threshold:\n",
    "      filtered_boxes.append(box)\n",
    "\n",
    "  return filtered_boxes  \n",
    "\n",
    "\n",
    "\n",
    "def get_bounding_box(mask):\n",
    "    non_zero_pixels = np.nonzero(mask)\n",
    "\n",
    "    min_row, min_col = np.min(non_zero_pixels, axis=1)\n",
    "    max_row, max_col = np.max(non_zero_pixels, axis=1)\n",
    "\n",
    "    # Return coordinates in desired format (x0, y0, x1, y1)\n",
    "    return min_col, min_row, max_col, max_row \n",
    "\n",
    "\n",
    "\n",
    "def segment_skin(image):\n",
    "  ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "  lower_thresh = (0, 133, 77)\n",
    "  upper_thresh = (255, 173, 127)\n",
    "\n",
    "  skin_mask = cv2.inRange(ycrcb, lower_thresh, upper_thresh)\n",
    "\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "  skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_OPEN, kernel, iterations=3)\n",
    "\n",
    "  return skin_mask\n",
    "\n",
    "\n",
    "\n",
    "def face_detection(frame) -> list:\n",
    "    \n",
    "    detected_faces = []\n",
    "\n",
    "    window_sizes = [(64, 64), (96, 96)]\n",
    "\n",
    "    skin_mask = segment_skin(frame)\n",
    "\n",
    "    x0, y0, x1, y1 = get_bounding_box(skin_mask)\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "\n",
    "        y_stride = window_size[0]\n",
    "        x_stride = window_size[1]\n",
    "\n",
    "        for y in range(y0, y1, y_stride):\n",
    "            for x in range(x0, x1, x_stride):\n",
    "                window = frame[y : y+window_size[0], x : x+window_size[1]]\n",
    "\n",
    "                [prediction] = face_classifer.predict( [extract_features_face_detection(window)] )\n",
    "\n",
    "                if prediction == 1:  \n",
    "                    detected_faces.append([x, y, x + window_size[1], y + window_size[0]])\n",
    "\n",
    "    detected_faces = filter_boxes_with_skin_mask(detected_faces, skin_mask)\n",
    "    detected_faces = union_boxes_min_max(detected_faces, x0, y0, x1, y1)\n",
    "\n",
    "    return detected_faces\n",
    "\n",
    "\n",
    "def YAWN_DETECTION_FOR_TRAINED(face,Appear_contours):\n",
    "    x=face[0]\n",
    "    y=face[1]\n",
    "    w=face[2]\n",
    "    h=face[3]\n",
    "    global sound_played\n",
    "    global yawn_counter\n",
    "    # Enlarge the face circle\n",
    "    scale_factor = 0.6\n",
    "    radius = int(max(w, h) * scale_factor)\n",
    "    center = (x + w // 2, y + h // 2)\n",
    "    if Appear_contours == 1:\n",
    "        cv2.circle(frame, center, radius, (255, 0, 0), 2)\n",
    "\n",
    "    # Define the region of interest for mouth detection \n",
    "    roi_face_rgb = rgb_frame[y + h//2 + h//4:y + h, x:x + w]\n",
    "\n",
    "    # Define the color range for detecting the mouth in RGB\n",
    "    lower_color = np.array([100, 50, 0], dtype=np.uint8)\n",
    "    upper_color = np.array([205, 130, 130], dtype=np.uint8)\n",
    "\n",
    "    # Create mask for the mouth region\n",
    "    mouth_mask = cv2.inRange(roi_face_rgb, lower_color, upper_color)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours,_ = cv2.findContours(mouth_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the contour with the largest area\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Check if the bounding box width and height are above a certain threshold\n",
    "        x_mouth, y_mouth, w_mouth, h_mouth = cv2.boundingRect(largest_contour)\n",
    "        if w_mouth > 20 and h_mouth > 20:\n",
    "            # Draw a rectangle around the detected mouth\n",
    "            if Appear_contours == 1:\n",
    "                cv2.rectangle(frame, (x + x_mouth, y + h//2 + h//4 + y_mouth), \n",
    "                          (x + x_mouth + w_mouth, y + h//2 + h//4 + y_mouth + h_mouth), (0, 255, 0), 1)\n",
    "\n",
    "            # Check for yawn based on mouth aspect ratio\n",
    "            mouth_aspect_ratio = calculate_mouth_aspect_ratio(largest_contour)\n",
    "            if h_mouth > 30 and not sound_played and mouth_aspect_ratio < 1.3 :\n",
    "                yawn_counter += 1\n",
    "                cv2.putText(frame, f'Yawn Count: {yawn_counter}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0),\n",
    "                            2, cv2.LINE_AA)\n",
    "\n",
    "                if yawn_counter > 40:\n",
    "                    pygame.mixer.Sound.play(buzzer_sound)\n",
    "                    sound_played = True  # Set the flag to True after playing the sound\n",
    "            else:\n",
    "                yawn_counter = 0\n",
    "                sound_played = False\n",
    " \n",
    "def YAWN_DETECTION_FOR_HAARCASC(face,Appear_contours):\n",
    "    global sound_played\n",
    "    global yawn_counter\n",
    "    for (x, y, w, h) in face:\n",
    "        # Enlarge the face circle\n",
    "        scale_factor = 0.6\n",
    "        radius = int(max(w, h) * scale_factor)\n",
    "        center = (x + w // 2, y + h // 2)\n",
    "        if Appear_contours == 1:\n",
    "            cv2.circle(frame, center, radius, (255, 0, 0), 2)\n",
    "        \n",
    "        # Define the region of interest for mouth detection \n",
    "        roi_face_rgb = rgb_frame[y + h//2 + h//4:y + h, x:x + w]\n",
    "\n",
    "        # Define the color range for detecting the mouth in RGB\n",
    "        lower_color = np.array([100, 50, 0], dtype=np.uint8)\n",
    "        upper_color = np.array([205, 130, 130], dtype=np.uint8)\n",
    "\n",
    "        # Create mask for the mouth region\n",
    "        mouth_mask = cv2.inRange(roi_face_rgb, lower_color, upper_color)\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours,_ = cv2.findContours(mouth_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Find the contour with the largest area\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # Check if the bounding box width and height are above a certain threshold\n",
    "            x_mouth, y_mouth, w_mouth, h_mouth = cv2.boundingRect(largest_contour)\n",
    "            if w_mouth > 20 and h_mouth > 20:\n",
    "                # Draw a rectangle around the detected mouth\n",
    "                if Appear_contours == 1:\n",
    "                    cv2.rectangle(frame, (x + x_mouth, y + h//2 + h//4 + y_mouth), \n",
    "                              (x + x_mouth + w_mouth, y + h//2 + h//4 + y_mouth + h_mouth), (0, 255, 0), 1)\n",
    "\n",
    "                # Check for yawn based on mouth aspect ratio\n",
    "                mouth_aspect_ratio = calculate_mouth_aspect_ratio(largest_contour)\n",
    "                if h_mouth > 30 and not sound_played and mouth_aspect_ratio < 1.3 :\n",
    "                    yawn_counter += 1\n",
    "                    cv2.putText(frame, f'Yawn Count: {yawn_counter}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0),\n",
    "                                2, cv2.LINE_AA)\n",
    "                    \n",
    "                    if yawn_counter > 40:\n",
    "                        pygame.mixer.Sound.play(buzzer_sound)\n",
    "                        sound_played = True  # Set the flag to True after playing the sound\n",
    "                else:\n",
    "                    yawn_counter = 0\n",
    "                    sound_played = False  # Reset the flag if no yawn is detected\n",
    "     \n",
    "def EYE_DETECTION_HAARCASC(face):\n",
    "    for (x, y, w, h) in face:\n",
    "        roi_gray = gray_frame[y:y + h, x:x + w]\n",
    "        # Extract the left and right eye coordinates\n",
    "        leftEye = roi_gray[5:11, 0:w]\n",
    "        rightEye = roi_gray[5:11, w - 6:w]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "        # Calculate the average intensity within the eye regions\n",
    "        average_intensity_left = np.mean(leftEye)\n",
    "        average_intensity_right = np.mean(rightEye)\n",
    "\n",
    "        # Define a threshold for the intensity change\n",
    "        intensity_threshold = 12\n",
    "\n",
    "        # Check for sudden changes in intensity\n",
    "        if abs(average_intensity_left - average_intensity_right) > intensity_threshold:\n",
    "            cv2.putText(frame, \"Awake\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"sleepy\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # Draw contours for the eyes inside the detected face region\n",
    "        leftEyeHull = cv2.convexHull(np.array([(30, 120), (30, 60), (w-30, 120), (w-30, 60)]))\n",
    "        rightEyeHull = cv2.convexHull(np.array([(30, 120), (30, 60), (w-30, 120), (w-30, 60)]))\n",
    "\n",
    "        cv2.drawContours(frame[y:y + h, x:x + w], [leftEyeHull], -1, (0, 255, 0), 2)\n",
    "        cv2.drawContours(frame[y:y + h, x:x + w], [rightEyeHull], -1, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "def EYE_DETECTION_TRAINED_FACE(face):\n",
    "    x=face[0]\n",
    "    y=face[1]\n",
    "    w=face[2]\n",
    "    h=face[3]\n",
    "    roi_gray = gray_frame[y:y + h, x:x + w]\n",
    "    # Extract the left and right eye coordinates\n",
    "    leftEye = roi_gray[5:11, 0:w]\n",
    "    rightEye = roi_gray[5:11, w - 6:w]\n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "    # Calculate the average intensity within the eye regions\n",
    "    average_intensity_left = np.mean(leftEye)\n",
    "    average_intensity_right = np.mean(rightEye)\n",
    "\n",
    "    # Define a threshold for the intensity change\n",
    "    intensity_threshold = 12\n",
    "\n",
    "    # Check for sudden changes in intensity\n",
    "    if abs(average_intensity_left - average_intensity_right) > intensity_threshold:\n",
    "        cv2.putText(frame, \"Awake\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, \"sleepy\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Draw contours for the eyes inside the detected face region\n",
    "    leftEyeHull = cv2.convexHull(np.array([(30, 120), (30, 60), (w-30, 120), (w-30, 60)]))\n",
    "    rightEyeHull = cv2.convexHull(np.array([(30, 120), (30, 60), (w-30, 120), (w-30, 60)]))\n",
    "\n",
    "    cv2.drawContours(frame[y:y + h, x:x + w], [leftEyeHull], -1, (0, 255, 0), 2)\n",
    "    cv2.drawContours(frame[y:y + h, x:x + w], [rightEyeHull], -1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Main Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omar saeed\\AppData\\Local\\Temp\\ipykernel_3144\\703565035.py:29: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  ear = (A + B) / (2.0 * C)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "yawn_counter=0\n",
    "sound_played = False\n",
    "\n",
    "while camera.isOpened():\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if HaarCascade == 1:\n",
    "        face = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)\n",
    "        YAWN_DETECTION_FOR_HAARCASC(face,0)\n",
    "        EYE_DETECTION_HAARCASC(face)\n",
    "    else:\n",
    "        face = face_detection(frame) # face -> (x0, y0, x1, y1)\n",
    "        YAWN_DETECTION_FOR_TRAINED(face,0)\n",
    "        EYE_DETECTION_TRAINED_FACE(face)\n",
    "\n",
    "\n",
    "    #cv2.rectangle(frame, (face[0], face[1]), (face[2], face[3]), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Stream\", frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        print(frame.shape)\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
