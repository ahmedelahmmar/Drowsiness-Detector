{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "face_classifer = joblib.load(\"../../models/Face Detector/FaceClassifier_HoG(64, 64)(16, 16)(8, 8)(0.95).pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = (64, 64) \n",
    "block_size = (16, 16)\n",
    "block_stride = (8, 8)\n",
    "cell_size = (8, 8)\n",
    "num_bins = 9\n",
    "\n",
    "HOG = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, num_bins)\n",
    "\n",
    "\n",
    "\n",
    "def extract_features_face_detection(Image):\n",
    "\n",
    "    gray_image = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    equalized_image = cv2.equalizeHist(gray_image)\n",
    "\n",
    "    resized_image = cv2.resize(equalized_image, win_size)\n",
    "        \n",
    "    feature = HOG.compute(resized_image).flatten()\n",
    "\n",
    "    if feature.max() > 0:\n",
    "        feature /= feature.max()\n",
    "\n",
    "    return feature\n",
    "\n",
    "\n",
    "\n",
    "def union_boxes_min_max(boxes, min_x, min_y, max_x, max_y):\n",
    "  overall_box = None\n",
    "\n",
    "  if not overall_box:\n",
    "    for box in boxes:\n",
    "      x_min, y_min, x_max, y_max = box\n",
    "      min_x = min(min_x, x_min)\n",
    "      min_y = min(min_y, y_min)\n",
    "      max_x = max(max_x, x_max)\n",
    "      max_y = max(max_y, y_max)\n",
    "    overall_box = (min_x, min_y, max_x, max_y)\n",
    "    \n",
    "    return overall_box\n",
    "\n",
    "\n",
    "\n",
    "def filter_boxes_with_skin_mask(boxes, skin_mask):\n",
    "  filtered_boxes = []\n",
    "  for box in boxes:\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    \n",
    "    box_area = (x_max - x_min) * (y_max - y_min)\n",
    "    \n",
    "    intersection_mask = skin_mask[y_min:y_max, x_min:x_max]\n",
    "    intersection_area = cv2.countNonZero(intersection_mask)\n",
    "    \n",
    "    iou = intersection_area / box_area\n",
    "\n",
    "    # Define threshold for acceptable overlap with skin mask\n",
    "    threshold = 0.5\n",
    "\n",
    "    if iou >= threshold:\n",
    "      filtered_boxes.append(box)\n",
    "\n",
    "  return filtered_boxes  \n",
    "\n",
    "\n",
    "\n",
    "def get_bounding_box(mask):\n",
    "    non_zero_pixels = np.nonzero(mask)\n",
    "\n",
    "    min_row, min_col = np.min(non_zero_pixels, axis=1)\n",
    "    max_row, max_col = np.max(non_zero_pixels, axis=1)\n",
    "\n",
    "    # Return coordinates in desired format (x0, y0, x1, y1)\n",
    "    return min_col, min_row, max_col, max_row \n",
    "\n",
    "\n",
    "\n",
    "def segment_skin(image):\n",
    "  ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "  lower_thresh = (0, 133, 77)\n",
    "  upper_thresh = (255, 173, 127)\n",
    "\n",
    "  skin_mask = cv2.inRange(ycrcb, lower_thresh, upper_thresh)\n",
    "\n",
    "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "  skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_OPEN, kernel, iterations=3)\n",
    "\n",
    "  return skin_mask\n",
    "\n",
    "\n",
    "\n",
    "def face_detection(frame) -> list:\n",
    "    \n",
    "    detected_faces = []\n",
    "\n",
    "    window_sizes = [(64, 64), (96, 96)]\n",
    "\n",
    "    skin_mask = segment_skin(frame)\n",
    "\n",
    "    x0, y0, x1, y1 = get_bounding_box(skin_mask)\n",
    "\n",
    "    for window_size in window_sizes:\n",
    "\n",
    "        y_stride = window_size[0]\n",
    "        x_stride = window_size[1]\n",
    "\n",
    "        for y in range(y0, y1, y_stride):\n",
    "            for x in range(x0, x1, x_stride):\n",
    "                window = frame[y : y+window_size[0], x : x+window_size[1]]\n",
    "\n",
    "                [prediction] = face_classifer.predict( [extract_features_face_detection(window)] )\n",
    "\n",
    "                if prediction == 1:  \n",
    "                    detected_faces.append([x, y, x + window_size[1], y + window_size[0]])\n",
    "\n",
    "    detected_faces = filter_boxes_with_skin_mask(detected_faces, skin_mask)\n",
    "    detected_faces = union_boxes_min_max(detected_faces, x0, y0, x1, y1)\n",
    "\n",
    "    return detected_faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Main Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while camera.isOpened():\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    face = face_detection(frame) # face -> (x0, y0, x1, y1)\n",
    "\n",
    "    cv2.rectangle(frame, (face[0], face[1]), (face[2], face[3]), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Stream\", frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        print(frame.shape)\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
